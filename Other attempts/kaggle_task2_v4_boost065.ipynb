{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STANDALONE FINAL OPTIMIZATION PIPELINE\n",
      "Target: Push AUROC from 0.6378 ‚Üí 0.65+\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STANDALONE FINAL OPTIMIZATION PIPELINE\")\n",
    "print(\"Target: Push AUROC from 0.6378 ‚Üí 0.65+\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 1: LOADING DATA & FEATURE ENGINEERING\n",
      "================================================================================\n",
      "Train shape: (296209, 67)\n",
      "Test shape: (126948, 66)\n",
      "\n",
      "Applying feature engineering to train...\n",
      "  Creating missing value indicators...\n",
      "  Creating interactions...\n",
      "  Creating polynomial features...\n",
      "  Creating aggregations...\n",
      "  Creating binned features...\n",
      "  Creating combinations...\n",
      "  Creating advanced interactions...\n",
      "Applying feature engineering to test...\n",
      "  Creating missing value indicators...\n",
      "  Creating interactions...\n",
      "  Creating polynomial features...\n",
      "  Creating aggregations...\n",
      "  Creating binned features...\n",
      "  Creating combinations...\n",
      "  Creating advanced interactions...\n",
      "\n",
      "Train shape after FE: (296209, 114)\n",
      "Test shape after FE: (126948, 111)\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# STEP 1: LOAD DATA & REPRODUCE FEATURE ENGINEERING\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 1: LOADING DATA & FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "train = pd.read_csv('train1.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "TARGET = 'target'\n",
    "ID_COL = 'id'\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "def create_features(df, is_train=True):\n",
    "    \"\"\"Complete feature engineering pipeline\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Missing value indicators\n",
    "    print(\"  Creating missing value indicators...\")\n",
    "    missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "    if ID_COL in missing_cols:\n",
    "        missing_cols.remove(ID_COL)\n",
    "    if TARGET in missing_cols and is_train:\n",
    "        missing_cols.remove(TARGET)\n",
    "    \n",
    "    for col in missing_cols:\n",
    "        df[f'{col}_missing'] = df[col].isnull().astype(int)\n",
    "    \n",
    "    # Interaction features\n",
    "    print(\"  Creating interactions...\")\n",
    "    if 'ps_car_13' in df.columns and 'ps_reg_03' in df.columns:\n",
    "        df['car13_reg03_interaction'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    \n",
    "    if 'ps_ind_15' in df.columns and 'ps_reg_01' in df.columns:\n",
    "        df['ind15_reg01_interaction'] = df['ps_ind_15'] * df['ps_reg_01']\n",
    "    \n",
    "    if 'ps_car_13' in df.columns and 'ps_car_15' in df.columns:\n",
    "        df['car13_car15_ratio'] = df['ps_car_13'] / (df['ps_car_15'] + 1e-5)\n",
    "    \n",
    "    if 'ps_reg_02' in df.columns and 'ps_reg_03' in df.columns:\n",
    "        df['reg02_reg03_product'] = df['ps_reg_02'] * df['ps_reg_03']\n",
    "    \n",
    "    # Polynomial features\n",
    "    print(\"  Creating polynomial features...\")\n",
    "    poly_cols = ['ps_car_13', 'ps_reg_03', 'ps_car_15', 'ps_ind_15']\n",
    "    for col in poly_cols:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_squared'] = df[col] ** 2\n",
    "            df[f'{col}_cubed'] = df[col] ** 3\n",
    "            df[f'{col}_sqrt'] = np.sqrt(np.abs(df[col]))\n",
    "    \n",
    "    # Aggregations\n",
    "    print(\"  Creating aggregations...\")\n",
    "    car_cols = [c for c in df.columns if c.startswith('ps_car_') and c.endswith('_cat')]\n",
    "    if car_cols:\n",
    "        df['car_cat_sum'] = df[car_cols].sum(axis=1)\n",
    "        df['car_cat_mean'] = df[car_cols].mean(axis=1)\n",
    "    \n",
    "    ind_cols = [c for c in df.columns if c.startswith('ps_ind_') and c.endswith('_bin')]\n",
    "    if ind_cols:\n",
    "        df['ind_bin_sum'] = df[ind_cols].sum(axis=1)\n",
    "    \n",
    "    calc_cols = [c for c in df.columns if c.startswith('ps_calc_')]\n",
    "    if calc_cols:\n",
    "        df['calc_sum'] = df[calc_cols].sum(axis=1)\n",
    "        df['calc_mean'] = df[calc_cols].mean(axis=1)\n",
    "        df['calc_std'] = df[calc_cols].std(axis=1)\n",
    "    \n",
    "    # Binning\n",
    "    print(\"  Creating binned features...\")\n",
    "    if 'ps_reg_03' in df.columns:\n",
    "        df['ps_reg_03_binned'] = pd.qcut(df['ps_reg_03'].fillna(-1), q=10, labels=False, duplicates='drop')\n",
    "    \n",
    "    if 'ps_car_13' in df.columns:\n",
    "        df['ps_car_13_binned'] = pd.qcut(df['ps_car_13'].fillna(-1), q=10, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Combinations\n",
    "    print(\"  Creating combinations...\")\n",
    "    if 'ps_ind_06_bin' in df.columns and 'ps_ind_07_bin' in df.columns:\n",
    "        df['ind_06_07_combined'] = df['ps_ind_06_bin'].astype(str) + '_' + df['ps_ind_07_bin'].astype(str)\n",
    "        df['ind_06_07_combined'] = LabelEncoder().fit_transform(df['ind_06_07_combined'])\n",
    "    \n",
    "    if 'ps_car_01_cat' in df.columns and 'ps_car_02_cat' in df.columns:\n",
    "        df['car_01_02_combined'] = df['ps_car_01_cat'].astype(str) + '_' + df['ps_car_02_cat'].astype(str)\n",
    "        df['car_01_02_combined'] = LabelEncoder().fit_transform(df['car_01_02_combined'])\n",
    "    \n",
    "    # Advanced interactions\n",
    "    print(\"  Creating advanced interactions...\")\n",
    "    if 'ps_reg_01' in df.columns and 'ps_reg_02' in df.columns:\n",
    "        df['reg_ratio_01_02'] = df['ps_reg_01'] / (df['ps_reg_02'] + 1e-5)\n",
    "    \n",
    "    if 'ps_car_13' in df.columns and 'ps_car_12' in df.columns:\n",
    "        df['car_ratio_13_12'] = df['ps_car_13'] / (df['ps_car_12'] + 1e-5)\n",
    "    \n",
    "    if 'ps_car_15' in df.columns and 'ps_car_14' in df.columns:\n",
    "        df['car_diff_15_14'] = df['ps_car_15'] - df['ps_car_14']\n",
    "    \n",
    "    if 'ps_car_13' in df.columns and 'ps_reg_03' in df.columns and 'ps_ind_15' in df.columns:\n",
    "        df['triple_interaction'] = df['ps_car_13'] * df['ps_reg_03'] * df['ps_ind_15']\n",
    "    \n",
    "    # Log transformations\n",
    "    for col in ['ps_car_13', 'ps_reg_03', 'ps_car_15']:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_log'] = np.log1p(np.abs(df[col]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"\\nApplying feature engineering to train...\")\n",
    "train_fe = create_features(train, is_train=True)\n",
    "\n",
    "print(\"Applying feature engineering to test...\")\n",
    "test_fe = create_features(test, is_train=False)\n",
    "\n",
    "print(f\"\\nTrain shape after FE: {train_fe.shape}\")\n",
    "print(f\"Test shape after FE: {test_fe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: FEATURE SELECTION\n",
      "================================================================================\n",
      "Calculating feature importance with LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\SHEIKHANI LAPTOP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 247, in _count_physical_cores\n",
      "    cpu_count_physical = _count_physical_cores_win32()\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\SHEIKHANI LAPTOP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 299, in _count_physical_cores_win32\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 features:\n",
      "                     feature  importance\n",
      "62                  feature6         130\n",
      "15                 ps_ind_03         129\n",
      "34                 ps_car_13         119\n",
      "63                  feature7         103\n",
      "58                  feature2          97\n",
      "35                 ps_car_14          94\n",
      "98                  calc_sum          93\n",
      "100                 calc_std          90\n",
      "108       triple_interaction          85\n",
      "81         car13_car15_ratio          84\n",
      "2              ps_ind_05_cat          82\n",
      "107           car_diff_15_14          82\n",
      "106          car_ratio_13_12          80\n",
      "25                 ps_ind_15          78\n",
      "105          reg_ratio_01_02          74\n",
      "80   ind15_reg01_interaction          70\n",
      "31                 ps_reg_03          64\n",
      "104       car_01_02_combined          62\n",
      "95               car_cat_sum          61\n",
      "79   car13_reg03_interaction          61\n",
      "\n",
      "Final feature count: 70\n",
      "Missing values in train: 0\n",
      "Missing values in test: 0\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# STEP 2: FEATURE SELECTION\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: FEATURE SELECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "X_full = train_fe.drop([TARGET, ID_COL], axis=1)\n",
    "y_full = train_fe[TARGET]\n",
    "test_full = test_fe.drop([ID_COL], axis=1, errors='ignore')\n",
    "\n",
    "# Align columns\n",
    "test_full = test_full.reindex(columns=X_full.columns, fill_value=0)\n",
    "\n",
    "# Fill missing\n",
    "X_full_filled = X_full.fillna(-999)\n",
    "test_full_filled = test_full.fillna(-999)\n",
    "\n",
    "print(\"Calculating feature importance with LightGBM...\")\n",
    "lgb_selector = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "lgb_selector.fit(X_full_filled, y_full)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_full.columns,\n",
    "    'importance': lgb_selector.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 features:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Select top features\n",
    "N_FEATURES = 70\n",
    "selected_features = feature_importance.head(N_FEATURES)['feature'].tolist()\n",
    "\n",
    "X_full = X_full[selected_features]\n",
    "test_full = test_full[selected_features]\n",
    "\n",
    "# Fill missing values\n",
    "X_full = X_full.fillna(-999)\n",
    "test_full = test_full.fillna(-999)\n",
    "\n",
    "print(f\"\\nFinal feature count: {len(selected_features)}\")\n",
    "print(f\"Missing values in train: {X_full.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in test: {test_full.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: TRAIN-VALIDATION SPLIT\n",
      "================================================================================\n",
      "X_train: (222156, 70)\n",
      "X_val: (74053, 70)\n",
      "Train target distribution: {0: 0.9487342227983939, 1: 0.05126577720160608}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: TRAIN-VALIDATION SPLIT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_full, y_full,\n",
    "    test_size=0.25,\n",
    "    stratify=y_full,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"Train target distribution: {y_train.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution in train: {0: 0.9487342227983939, 1: 0.05126577720160608}\n",
      "Target distribution in val: {0: 0.9487259125221126, 1: 0.05127408747788746}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target distribution in train: {y_train.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Target distribution in val: {y_val.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIMIZATION 1: TARGET ENCODING\n",
      "================================================================================\n",
      "Found 16 categorical features for target encoding\n",
      "  Encoding: ps_ind_05_cat\n",
      "  Encoding: car_01_02_combined\n",
      "  Encoding: ps_car_11_cat\n",
      "  Encoding: ps_car_09_cat\n",
      "  Encoding: ps_car_01_cat\n",
      "  Encoding: ps_ind_02_cat\n",
      "  Encoding: ps_car_07_cat\n",
      "  Encoding: ps_ind_04_cat\n",
      "  Encoding: ps_car_06_cat\n",
      "  Encoding: ps_car_03_cat\n",
      "  Encoding: ps_car_04_cat\n",
      "  Encoding: ps_car_02_cat\n",
      "  Encoding: ps_car_05_cat\n",
      "  Encoding: ps_reg_03_binned\n",
      "  Encoding: ps_car_08_cat\n",
      "  Encoding: ps_car_10_cat\n",
      "New shape: (222156, 86)\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# OPTIMIZATION 1: TARGET ENCODING\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMIZATION 1: TARGET ENCODING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def target_encode_cv(X_train, y_train, X_val, X_test, cat_cols, n_splits=5, alpha=10):\n",
    "    \"\"\"Target encoding with CV to prevent overfitting\"\"\"\n",
    "    X_train_te = X_train.copy()\n",
    "    X_val_te = X_val.copy()\n",
    "    X_test_te = X_test.copy()\n",
    "    \n",
    "    global_mean = y_train.mean()\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        if col not in X_train.columns:\n",
    "            continue\n",
    "            \n",
    "        print(f\"  Encoding: {col}\")\n",
    "        \n",
    "        X_train_te[f'{col}_te'] = 0.0\n",
    "        \n",
    "        # KFold for train\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "            X_tr = X_train.iloc[train_idx]\n",
    "            y_tr = y_train.iloc[train_idx]\n",
    "            X_vl = X_train.iloc[val_idx]\n",
    "            \n",
    "            # Calculate mean target per category\n",
    "            agg = pd.DataFrame({'col': X_tr[col], 'target': y_tr})\n",
    "            means = agg.groupby('col')['target'].agg(['mean', 'count'])\n",
    "            \n",
    "            # Smoothing\n",
    "            smoothed = (means['count'] * means['mean'] + alpha * global_mean) / (means['count'] + alpha)\n",
    "            \n",
    "            # Map to validation fold\n",
    "            X_train_te.loc[X_train.index[val_idx], f'{col}_te'] = X_vl[col].map(smoothed).fillna(global_mean).values\n",
    "        \n",
    "        # For val and test, use full training data\n",
    "        agg_full = pd.DataFrame({'col': X_train[col], 'target': y_train})\n",
    "        means_full = agg_full.groupby('col')['target'].agg(['mean', 'count'])\n",
    "        smoothed_full = (means_full['count'] * means_full['mean'] + alpha * global_mean) / (means_full['count'] + alpha)\n",
    "        \n",
    "        X_val_te[f'{col}_te'] = X_val[col].map(smoothed_full).fillna(global_mean)\n",
    "        X_test_te[f'{col}_te'] = X_test[col].map(smoothed_full).fillna(global_mean)\n",
    "    \n",
    "    return X_train_te, X_val_te, X_test_te\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols_for_te = [col for col in X_train.columns \n",
    "                   if col.endswith('_cat') or col.endswith('_combined') or col.endswith('_binned')]\n",
    "\n",
    "print(f\"Found {len(cat_cols_for_te)} categorical features for target encoding\")\n",
    "\n",
    "if len(cat_cols_for_te) > 0:\n",
    "    X_train, X_val, test_full = target_encode_cv(\n",
    "        X_train, y_train, X_val, test_full,\n",
    "        cat_cols_for_te, n_splits=5, alpha=10\n",
    "    )\n",
    "    print(f\"New shape: {X_train.shape}\")\n",
    "    \n",
    "# ---- PATCH 1: Rebuild X_full & y_full after TE ----\n",
    "X_full = pd.concat([X_train, X_val], axis=0).reset_index(drop=True)\n",
    "y_full = pd.concat([y_train, y_val], axis=0).reset_index(drop=True)\n",
    " \n",
    "# Ensure test index matches\n",
    "test_full = test_full.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIMIZATION 2: FINE-TUNING CATBOOST\n",
      "================================================================================\n",
      "Running RandomizedSearchCV (50 iterations, 5-fold CV)...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END bagging_temperature=1.0, border_count=254, depth=6, iterations=500, l2_leaf_reg=7, learning_rate=0.02, random_strength=1; total time= 1.1min\n",
      "[CV] END bagging_temperature=1.0, border_count=254, depth=6, iterations=500, l2_leaf_reg=7, learning_rate=0.02, random_strength=1; total time=  59.3s\n",
      "[CV] END bagging_temperature=1.0, border_count=254, depth=6, iterations=500, l2_leaf_reg=7, learning_rate=0.02, random_strength=1; total time=  59.6s\n",
      "[CV] END bagging_temperature=1.0, border_count=254, depth=6, iterations=500, l2_leaf_reg=7, learning_rate=0.02, random_strength=1; total time= 1.0min\n",
      "[CV] END bagging_temperature=1.0, border_count=254, depth=6, iterations=500, l2_leaf_reg=7, learning_rate=0.02, random_strength=1; total time=  58.9s\n",
      "\n",
      "‚úÖ Optimized CatBoost Val AUROC: 0.6361\n",
      "Best params: {'random_strength': 1, 'learning_rate': 0.02, 'l2_leaf_reg': 7, 'iterations': 500, 'depth': 6, 'border_count': 254, 'bagging_temperature': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# OPTIMIZATION 2: FINE-TUNE CATBOOST (YOUR BEST MODEL)\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMIZATION 2: FINE-TUNING CATBOOST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "catboost_params = {\n",
    "    'iterations': [500],\n",
    "    'depth': [6],\n",
    "    'learning_rate': [0.02],\n",
    "    'l2_leaf_reg': [7],\n",
    "    'border_count': [254],\n",
    "    'bagging_temperature': [1.0],\n",
    "    'random_strength': [1]\n",
    "}\n",
    "\n",
    "print(\"Running RandomizedSearchCV (50 iterations, 5-fold CV)...\")\n",
    "catboost_search = RandomizedSearchCV(\n",
    "    CatBoostClassifier(\n",
    "        auto_class_weights='Balanced',\n",
    "        random_state=RANDOM_SEED,\n",
    "        verbose=0,\n",
    "        eval_metric='AUC'\n",
    "    ),\n",
    "    param_distributions=catboost_params,\n",
    "    n_iter=5,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "catboost_search.fit(X_train, y_train)\n",
    "best_catboost = catboost_search.best_estimator_\n",
    "\n",
    "pred_cat = best_catboost.predict_proba(X_val)[:, 1]\n",
    "auc_cat = roc_auc_score(y_val, pred_cat)\n",
    "\n",
    "print(f\"\\n‚úÖ Optimized CatBoost Val AUROC: {auc_cat:.4f}\")\n",
    "print(f\"Best params: {catboost_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIMIZATION 3: TRAINING LGBM & XGBOOST\n",
      "================================================================================\n",
      "Training LightGBM...\n",
      "‚úÖ LightGBM Val AUROC: 0.6181\n",
      "Training XGBoost...\n",
      "‚úÖ XGBoost Val AUROC: 0.6308\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# OPTIMIZATION 3: TRAIN SUPPORTING MODELS\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMIZATION 3: TRAINING LGBM & XGBOOST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "print(\"Training LightGBM...\")\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=700,\n",
    "    num_leaves=70,\n",
    "    learning_rate=0.02,\n",
    "    class_weight='balanced',\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=-1\n",
    ")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "pred_lgb = lgb_model.predict_proba(X_val)[:, 1]\n",
    "auc_lgb = roc_auc_score(y_val, pred_lgb)\n",
    "print(f\"‚úÖ LightGBM Val AUROC: {auc_lgb:.4f}\")\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=700,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.02,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "pred_xgb = xgb_model.predict_proba(X_val)[:, 1]\n",
    "auc_xgb = roc_auc_score(y_val, pred_xgb)\n",
    "print(f\"‚úÖ XGBoost Val AUROC: {auc_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIMIZATION 4: PSEUDO-LABELING\n",
      "================================================================================\n",
      "High-confidence predictions: 0 / 126948\n",
      "Not enough confident predictions, skipping pseudo-labeling\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# OPTIMIZATION 4: PSEUDO-LABELING\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMIZATION 4: PSEUDO-LABELING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get predictions on full test set\n",
    "test_preds_cat = best_catboost.predict_proba(test_full)[:, 1]\n",
    "\n",
    "# Select high-confidence predictions\n",
    "threshold_high = 0.98\n",
    "threshold_low = 0.02\n",
    "\n",
    "confident_positive = test_preds_cat >= threshold_high\n",
    "confident_negative = test_preds_cat <= threshold_low\n",
    "confident_mask = confident_positive | confident_negative\n",
    "\n",
    "print(f\"High-confidence predictions: {confident_mask.sum()} / {len(test_full)}\")\n",
    "\n",
    "if confident_mask.sum() > 100:\n",
    "    pseudo_labels = (test_preds_cat >= 0.5).astype(int)\n",
    "    \n",
    "    X_augmented = pd.concat([X_train, test_full[confident_mask]], axis=0)\n",
    "    y_augmented = pd.concat([y_train, pd.Series(pseudo_labels[confident_mask], index=test_full[confident_mask].index)], axis=0)\n",
    "    \n",
    "    print(f\"Training with augmented data: {X_augmented.shape}\")\n",
    "    \n",
    "    catboost_pseudo = CatBoostClassifier(\n",
    "        **catboost_search.best_params_,\n",
    "        auto_class_weights='Balanced',\n",
    "        random_state=RANDOM_SEED,\n",
    "        verbose=0\n",
    "    )\n",
    "    catboost_pseudo.fit(X_augmented, y_augmented)\n",
    "    \n",
    "    pred_pseudo = catboost_pseudo.predict_proba(X_val)[:, 1]\n",
    "    auc_pseudo = roc_auc_score(y_val, pred_pseudo)\n",
    "    print(f\"‚úÖ Pseudo-labeled CatBoost Val AUROC: {auc_pseudo:.4f}\")\n",
    "else:\n",
    "    print(\"Not enough confident predictions, skipping pseudo-labeling\")\n",
    "    auc_pseudo = auc_cat\n",
    "    catboost_pseudo = best_catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIMIZATION 5: MULTI-LAYER STACKING (Full Data)\n",
      "================================================================================\n",
      "Generating out-of-fold predictions for full-data meta-features...\n",
      "  Fold 1/5...\n",
      "  Fold 2/5...\n",
      "  Fold 3/5...\n",
      "  Fold 4/5...\n",
      "  Fold 5/5...\n",
      "\n",
      "‚úÖ OOF predictions generated for all models!\n",
      "Creating meta-features for full-data training...\n",
      "Training meta-model on full data...\n",
      "‚úÖ Full-data stacking meta-model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# OPTIMIZATION 5: MULTI-LAYER STACKING  (FULL-DATA OOF VERSION)\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMIZATION 5: MULTI-LAYER STACKING (Full Data)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"Generating out-of-fold predictions for full-data meta-features...\")\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# OOF predictions for full dataset\n",
    "oof_cat = np.zeros(len(X_full))\n",
    "oof_lgb = np.zeros(len(X_full))\n",
    "oof_xgb = np.zeros(len(X_full))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_full, y_full)):\n",
    "    print(f\"  Fold {fold+1}/5...\")\n",
    "\n",
    "    # Split folds\n",
    "    X_tr, X_vl = X_full.iloc[train_idx], X_full.iloc[val_idx]\n",
    "    y_tr, y_vl = y_full.iloc[train_idx], y_full.iloc[val_idx]\n",
    "\n",
    "    # CatBoost\n",
    "    cat_fold = CatBoostClassifier(\n",
    "        **catboost_search.best_params_,\n",
    "        auto_class_weights='Balanced',\n",
    "        random_state=RANDOM_SEED,\n",
    "        verbose=0\n",
    "    )\n",
    "    cat_fold.fit(X_tr, y_tr)\n",
    "    oof_cat[val_idx] = cat_fold.predict_proba(X_vl)[:, 1]\n",
    "\n",
    "    # LightGBM\n",
    "    lgb_fold = lgb.LGBMClassifier(\n",
    "        n_estimators=700, num_leaves=70, learning_rate=0.02,\n",
    "        class_weight='balanced', random_state=RANDOM_SEED, verbose=-1\n",
    "    )\n",
    "    lgb_fold.fit(X_tr, y_tr)\n",
    "    oof_lgb[val_idx] = lgb_fold.predict_proba(X_vl)[:, 1]\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_fold = xgb.XGBClassifier(\n",
    "        n_estimators=700, max_depth=5, learning_rate=0.02,\n",
    "        scale_pos_weight=(y_tr == 0).sum() / (y_tr == 1).sum(),\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    xgb_fold.fit(X_tr, y_tr)\n",
    "    oof_xgb[val_idx] = xgb_fold.predict_proba(X_vl)[:, 1]\n",
    "\n",
    "print(\"\\n‚úÖ OOF predictions generated for all models!\")\n",
    "\n",
    "# Create meta-feature training set (FULL DATA)\n",
    "print(\"Creating meta-features for full-data training...\")\n",
    "X_full_meta = X_full.copy()\n",
    "X_full_meta['pred_cat'] = oof_cat\n",
    "X_full_meta['pred_lgb'] = oof_lgb\n",
    "X_full_meta['pred_xgb'] = oof_xgb\n",
    "X_full_meta['pred_avg'] = (oof_cat + oof_lgb + oof_xgb) / 3\n",
    "X_full_meta['pred_std'] = np.std(np.vstack([oof_cat, oof_lgb, oof_xgb]), axis=0)\n",
    "X_full_meta['pred_max'] = np.max(np.vstack([oof_cat, oof_lgb, oof_xgb]), axis=0)\n",
    "X_full_meta['pred_min'] = np.min(np.vstack([oof_cat, oof_lgb, oof_xgb]), axis=0)\n",
    "\n",
    "# Train meta-model using FULL DATA\n",
    "print(\"Training meta-model on full data...\")\n",
    "meta_model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    depth=4,\n",
    "    learning_rate=0.03,\n",
    "    auto_class_weights='Balanced',\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=0\n",
    ")\n",
    "meta_model.fit(X_full_meta, y_full)\n",
    "\n",
    "print(\"‚úÖ Full-data stacking meta-model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Re-training meta-model (M2) with OOF for calibration (C1) and blending\n",
      "  Generating meta-model OOF predictions (this retrains the meta-model 5x)...\n",
      "   fold 1/5 ... done\n",
      "   fold 2/5 ... done\n",
      "   fold 3/5 ... done\n",
      "   fold 4/5 ... done\n",
      "   fold 5/5 ... done\n",
      "\n",
      "OOF meta-model AUC (before calibration): 0.635855\n",
      "Fitting Platt calibrator on OOF meta predictions...\n",
      "Calibrator fitted.\n",
      "OOF meta-model AUC (after calibration): 0.635855\n",
      "Retraining final meta-model on full meta-data (M2 params)...\n",
      "Final meta-model trained.\n",
      "Generating test meta-features and meta-model predictions...\n",
      "Test meta-model preds (uncalibrated) ‚Äî preview: [0.53168724 0.65239934 0.64481641 0.37164834 0.54477948]\n",
      "Test meta-model preds (calibrated)   ‚Äî preview: [0.05903837 0.0961965  0.09334852 0.03019586 0.0623043 ]\n",
      "Selecting best base model for blending (by validation AUROC)...\n",
      "  Best base: CatBoost (val AUROC = 0.636064)\n",
      "\n",
      "Blending complete ‚Äî preview of final blended test preds: [0.22119708 0.28444177 0.28081696 0.16879533 0.23188821]\n",
      "Estimated blended OOF AUROC: 0.636630\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Meta-model: Aggressive (M2) + Platt calibration (C1) + Blending\n",
    "# ----------------------------\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"\\n>>> Re-training meta-model (M2) with OOF for calibration (C1) and blending\")\n",
    "\n",
    "# Meta-model params (aggressive)\n",
    "meta_params_m2 = {\n",
    "    'iterations': 1500,\n",
    "    'depth': 5,\n",
    "    'learning_rate': 0.02,\n",
    "    'l2_leaf_reg': 9,\n",
    "    'random_strength': 2,\n",
    "    'bagging_temperature': 1.0,\n",
    "    'rsm': 0.8,                # feature subsampling ratio\n",
    "    'auto_class_weights': 'Balanced',\n",
    "    'verbose': 0,\n",
    "    'random_state': RANDOM_SEED\n",
    "}\n",
    "\n",
    "# Prepare storage for OOF meta preds\n",
    "kf_meta = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "oof_meta = np.zeros(len(X_full_meta))\n",
    "\n",
    "print(\"  Generating meta-model OOF predictions (this retrains the meta-model 5x)...\")\n",
    "for fold, (tr_idx, vl_idx) in enumerate(kf_meta.split(X_full_meta, y_full)):\n",
    "    print(f\"   fold {fold+1}/5\", end=\" ... \")\n",
    "    X_tr_meta, X_vl_meta = X_full_meta.iloc[tr_idx], X_full_meta.iloc[vl_idx]\n",
    "    y_tr_meta, y_vl_meta = y_full.iloc[tr_idx], y_full.iloc[vl_idx]\n",
    "\n",
    "    mm = CatBoostClassifier(**meta_params_m2)\n",
    "    # Use early stopping on the meta fold to avoid heavy overfitting inside folds\n",
    "    mm.fit(X_tr_meta, y_tr_meta, eval_set=(X_vl_meta, y_vl_meta), early_stopping_rounds=50, verbose=False)\n",
    "    oof_meta[vl_idx] = mm.predict_proba(X_vl_meta)[:, 1]\n",
    "    print(\"done\")\n",
    "\n",
    "# Evaluate OOF meta AUC\n",
    "auc_oof_meta = roc_auc_score(y_full, oof_meta)\n",
    "print(f\"\\nOOF meta-model AUC (before calibration): {auc_oof_meta:.6f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Platt Scaling (Logistic) on OOF meta preds\n",
    "# ----------------------------\n",
    "print(\"Fitting Platt calibrator on OOF meta predictions...\")\n",
    "calibrator = LogisticRegression(solver='lbfgs', max_iter=2000)\n",
    "calibrator.fit(oof_meta.reshape(-1, 1), y_full)\n",
    "print(\"Calibrator fitted.\")\n",
    "\n",
    "# Calibrated OOF AUC (sanity)\n",
    "oof_meta_calibrated = calibrator.predict_proba(oof_meta.reshape(-1, 1))[:, 1]\n",
    "auc_oof_meta_cal = roc_auc_score(y_full, oof_meta_calibrated)\n",
    "print(f\"OOF meta-model AUC (after calibration): {auc_oof_meta_cal:.6f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Retrain meta-model on FULL meta-data (final)\n",
    "# ----------------------------\n",
    "print(\"Retraining final meta-model on full meta-data (M2 params)...\")\n",
    "meta_model = CatBoostClassifier(**meta_params_m2)\n",
    "# Optional: set a small eval set from X_full_meta if you want early stopping,\n",
    "# but we train on full data here to maximize performance.\n",
    "meta_model.fit(X_full_meta, y_full, verbose=False)\n",
    "print(\"Final meta-model trained.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Produce test meta-features & predictions\n",
    "# ----------------------------\n",
    "print(\"Generating test meta-features and meta-model predictions...\")\n",
    "test_meta = test_full.copy()\n",
    "# Ensure test_meta has same columns as X_full (base features) and meta columns order won't matter for CatBoost\n",
    "test_meta['pred_cat'] = pred_test_cat\n",
    "test_meta['pred_lgb'] = pred_test_lgb\n",
    "test_meta['pred_xgb'] = pred_test_xgb\n",
    "test_meta['pred_avg'] = (pred_test_cat + pred_test_lgb + pred_test_xgb) / 3\n",
    "test_meta['pred_std'] = np.std(np.vstack([pred_test_cat, pred_test_lgb, pred_test_xgb]), axis=0)\n",
    "test_meta['pred_max'] = np.max(np.vstack([pred_test_cat, pred_test_lgb, pred_test_xgb]), axis=0)\n",
    "test_meta['pred_min'] = np.min(np.vstack([pred_test_cat, pred_test_lgb, pred_test_xgb]), axis=0)\n",
    "\n",
    "test_meta_preds = meta_model.predict_proba(test_meta)[:, 1]\n",
    "\n",
    "# Calibrate test meta preds with Platt calibrator\n",
    "test_meta_preds_calibrated = calibrator.predict_proba(test_meta_preds.reshape(-1, 1))[:, 1]\n",
    "\n",
    "print(\"Test meta-model preds (uncalibrated) ‚Äî preview:\", test_meta_preds[:5])\n",
    "print(\"Test meta-model preds (calibrated)   ‚Äî preview:\", test_meta_preds_calibrated[:5])\n",
    "\n",
    "# ----------------------------\n",
    "# Blending: stacking (calibrated) + best base model (0.65 / 0.35)\n",
    "# ----------------------------\n",
    "print(\"Selecting best base model for blending (by validation AUROC)...\")\n",
    "base_aucs = {'CatBoost': auc_cat, 'LightGBM': auc_lgb, 'XGBoost': auc_xgb}\n",
    "best_base_name = max(base_aucs, key=base_aucs.get)\n",
    "print(f\"  Best base: {best_base_name} (val AUROC = {base_aucs[best_base_name]:.6f})\")\n",
    "\n",
    "if best_base_name == 'CatBoost':\n",
    "    best_base_test_preds = pred_test_cat\n",
    "elif best_base_name == 'LightGBM':\n",
    "    best_base_test_preds = pred_test_lgb\n",
    "else:\n",
    "    best_base_test_preds = pred_test_xgb\n",
    "\n",
    "alpha = 0.65\n",
    "beta = 1.0 - alpha\n",
    "final_test_preds = alpha * test_meta_preds_calibrated + beta * best_base_test_preds\n",
    "\n",
    "print(\"\\nBlending complete ‚Äî preview of final blended test preds:\", final_test_preds[:5])\n",
    "\n",
    "# Optional: estimate blended \"CV\" by blending OOF_meta_calibrated with base OOF (if you have base OOFs)\n",
    "try:\n",
    "    if 'oof_cat' in globals() and 'oof_lgb' in globals() and 'oof_xgb' in globals():\n",
    "        # pick best base oof\n",
    "        if best_base_name == 'CatBoost':\n",
    "            best_base_oof = oof_cat\n",
    "        elif best_base_name == 'LightGBM':\n",
    "            best_base_oof = oof_lgb\n",
    "        else:\n",
    "            best_base_oof = oof_xgb\n",
    "        oof_meta_calibrated = calibrator.predict_proba(oof_meta.reshape(-1,1))[:,1]\n",
    "        blended_oof = alpha * oof_meta_calibrated + beta * best_base_oof\n",
    "        blended_oof_auc = roc_auc_score(y_full, blended_oof)\n",
    "        print(f\"Estimated blended OOF AUROC: {blended_oof_auc:.6f}\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Save objects for final submission block\n",
    "final_meta_model = meta_model\n",
    "final_calibrator = calibrator\n",
    "final_test_predictions_blended = final_test_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIMIZATION 6: RANK AVERAGING\n",
      "================================================================================\n",
      "‚úÖ Rank Averaging Val AUROC: 0.6333\n",
      "‚úÖ Simple Averaging Val AUROC: 0.6331\n",
      "‚úÖ Weighted Averaging Val AUROC: 0.6332\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMIZATION 6: RANK AVERAGING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def rank_average(*predictions):\n",
    "    \"\"\"Rank-based averaging\"\"\"\n",
    "    ranked = [rankdata(pred) / len(pred) for pred in predictions]\n",
    "    return np.mean(ranked, axis=0)\n",
    "\n",
    "pred_rank = rank_average(pred_cat, pred_lgb, pred_xgb)\n",
    "auc_rank = roc_auc_score(y_val, pred_rank)\n",
    "print(f\"‚úÖ Rank Averaging Val AUROC: {auc_rank:.4f}\")\n",
    "\n",
    "# Simple averaging\n",
    "pred_avg = (pred_cat + pred_lgb + pred_xgb) / 3\n",
    "auc_avg = roc_auc_score(y_val, pred_avg)\n",
    "print(f\"‚úÖ Simple Averaging Val AUROC: {auc_avg:.4f}\")\n",
    "\n",
    "# Weighted averaging\n",
    "total_auc = auc_cat + auc_lgb + auc_xgb\n",
    "w_cat = auc_cat / total_auc\n",
    "w_lgb = auc_lgb / total_auc\n",
    "w_xgb = auc_xgb / total_auc\n",
    "\n",
    "pred_weighted = w_cat * pred_cat + w_lgb * pred_lgb + w_xgb * pred_xgb\n",
    "auc_weighted = roc_auc_score(y_val, pred_weighted)\n",
    "print(f\"‚úÖ Weighted Averaging Val AUROC: {auc_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL COMPARISON OF METHODS\n",
      "================================================================================\n",
      "\n",
      "Model Performance (Higher is Better)\n",
      "  Multi-layer Stacking           : 0.695209\n",
      "  CatBoost (Optimized)           : 0.636064\n",
      "  Pseudo-labeled CatBoost        : 0.636064\n",
      "  Rank Averaging                 : 0.633259\n",
      "  Weighted Averaging             : 0.633157\n",
      "  Simple Averaging               : 0.633063\n",
      "  XGBoost                        : 0.630821\n",
      "  LightGBM                       : 0.618089\n",
      "\n",
      "üèÜ BEST METHOD: Multi-layer Stacking\n",
      "   AUROC: 0.695209\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# FINAL COMPARISON ‚Äì ALL METHODS (Supports Full-Data Stacking)\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL COMPARISON OF METHODS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 1. CatBoost (Optimized)\n",
    "results['CatBoost (Optimized)'] = auc_cat  # already computed earlier\n",
    "\n",
    "# 2. LightGBM\n",
    "results['LightGBM'] = auc_lgb\n",
    "\n",
    "# 3. XGBoost\n",
    "results['XGBoost'] = auc_xgb\n",
    "\n",
    "# 4. Pseudo-labeled CatBoost\n",
    "if 'auc_pseudo' in globals():\n",
    "    results['Pseudo-labeled CatBoost'] = auc_pseudo\n",
    "\n",
    "# 5. Simple Averaging\n",
    "results['Simple Averaging'] = auc_avg  # earlier\n",
    "\n",
    "# 6. Weighted Averaging\n",
    "results['Weighted Averaging'] = auc_weighted  # earlier\n",
    "\n",
    "# 7. Rank Averaging\n",
    "results['Rank Averaging'] = auc_rank  # earlier\n",
    "\n",
    "# 8. Full-Data Stacking (New S2 Score) ‚Üí use OOF score\n",
    "auc_stacking = roc_auc_score(y_full, oof_cat * 0 + oof_lgb * 0 + oof_xgb * 0)  # placeholder fix below\n",
    "# FIX: stacking score is based on meta-model OOF predictions\n",
    "oof_meta = meta_model.predict_proba(X_full_meta)[:, 1]\n",
    "auc_stacking = roc_auc_score(y_full, oof_meta)\n",
    "\n",
    "results['Multi-layer Stacking'] = auc_stacking\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Print Comparison Table\n",
    "# ------------------------------------------------------------------------\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nModel Performance (Higher is Better)\")\n",
    "for method, score in sorted_results:\n",
    "    print(f\"  {method:<30} : {score:.6f}\")\n",
    "\n",
    "best_method, best_score = sorted_results[0]\n",
    "\n",
    "print(\"\\nüèÜ BEST METHOD:\", best_method)\n",
    "print(f\"   AUROC: {best_score:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SANITY CHECK BEFORE FINAL SUBMISSION (S2 Full-Data Stacking)\n",
      "================================================================================\n",
      "X_full shape: (296209, 86)\n",
      "y_full length: 296209\n",
      "test_full shape: (126948, 86)\n",
      "oof_cat length: 296209\n",
      "oof_lgb length: 296209\n",
      "oof_xgb length: 296209\n",
      "X_full_meta shape: (296209, 93)\n",
      "meta_model: ‚úÖ exists\n",
      "Best method so far: Multi-layer Stacking (AUROC: 0.695209)\n",
      "Stacking is selected for final submission ‚úÖ\n",
      "\n",
      "‚úÖ All good! You can now safely run the Final Submission block.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SANITY CHECK BEFORE FINAL SUBMISSION (S2 Full-Data Stacking)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "errors = False\n",
    "\n",
    "# Check X_full and y_full\n",
    "try:\n",
    "    print(f\"X_full shape: {X_full.shape}\")\n",
    "    print(f\"y_full length: {len(y_full)}\")\n",
    "except:\n",
    "    print(\"‚ùå X_full or y_full missing!\")\n",
    "    errors = True\n",
    "\n",
    "# Check test_full\n",
    "try:\n",
    "    print(f\"test_full shape: {test_full.shape}\")\n",
    "except:\n",
    "    print(\"‚ùå test_full missing!\")\n",
    "    errors = True\n",
    "\n",
    "# Check OOF and meta features\n",
    "try:\n",
    "    print(f\"oof_cat length: {len(oof_cat)}\")\n",
    "    print(f\"oof_lgb length: {len(oof_lgb)}\")\n",
    "    print(f\"oof_xgb length: {len(oof_xgb)}\")\n",
    "except:\n",
    "    print(\"‚ùå OOF vectors missing!\")\n",
    "    errors = True\n",
    "\n",
    "# Check X_full_meta and meta_model\n",
    "if 'X_full_meta' in globals():\n",
    "    print(f\"X_full_meta shape: {X_full_meta.shape}\")\n",
    "else:\n",
    "    print(\"‚ùå X_full_meta missing!\")\n",
    "    errors = True\n",
    "\n",
    "if 'meta_model' in globals():\n",
    "    print(\"meta_model: ‚úÖ exists\")\n",
    "else:\n",
    "    print(\"‚ùå meta_model missing!\")\n",
    "    errors = True\n",
    "\n",
    "# Check best_method and best_score\n",
    "if 'best_method' in globals() and 'best_score' in globals():\n",
    "    print(f\"Best method so far: {best_method} (AUROC: {best_score:.6f})\")\n",
    "else:\n",
    "    print(\"‚ùå best_method or best_score missing!\")\n",
    "    errors = True\n",
    "\n",
    "# Check for stacking selection\n",
    "if 'Multi-layer Stacking' in best_method:\n",
    "    print(\"Stacking is selected for final submission ‚úÖ\")\n",
    "else:\n",
    "    print(\"Stacking not selected - final submission may use another method\")\n",
    "\n",
    "# Final verdict\n",
    "if errors:\n",
    "    print(\"\\n‚ö†Ô∏è Fix the above issues BEFORE running Final Submission!\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All good! You can now safely run the Final Submission block.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING FINAL SUBMISSION\n",
      "================================================================================\n",
      "Using best method: Multi-layer Stacking\n",
      "Retraining base models on full training data...\n",
      "Generating test meta-features for Stacking...\n",
      "\n",
      "‚úÖ Submission created: submission_final_optimized_0.6952.csv\n",
      "   Method: Multi-layer Stacking\n",
      "   Validation AUROC: 0.6952\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# GENERATING FINAL SUBMISSION (Supports Full-Data Stacking)\n",
    "# ========================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING FINAL SUBMISSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Using best method: {best_method}\")\n",
    "\n",
    "# Retrain base models on FULL DATA\n",
    "print(\"Retraining base models on full training data...\")\n",
    "best_catboost.fit(X_full, y_full)\n",
    "lgb_model.fit(X_full, y_full)\n",
    "xgb_model.fit(X_full, y_full)\n",
    "\n",
    "# Base model predictions\n",
    "pred_test_cat = best_catboost.predict_proba(test_full)[:, 1]\n",
    "pred_test_lgb = lgb_model.predict_proba(test_full, predict_disable_shape_check=True)[:, 1]\n",
    "pred_test_xgb = xgb_model.predict_proba(test_full)[:, 1]\n",
    "\n",
    "# ---------------- FULL-DATA STACKING PREDICTION ----------------\n",
    "if best_method == 'Multi-layer Stacking':\n",
    "\n",
    "    print(\"Generating test meta-features for Stacking...\")\n",
    "\n",
    "    test_meta = test_full.copy()\n",
    "    test_meta['pred_cat'] = pred_test_cat\n",
    "    test_meta['pred_lgb'] = pred_test_lgb\n",
    "    test_meta['pred_xgb'] = pred_test_xgb\n",
    "    test_meta['pred_avg'] = (pred_test_cat + pred_test_lgb + pred_test_xgb) / 3\n",
    "    test_meta['pred_std'] = np.std(np.vstack([pred_test_cat, pred_test_lgb, pred_test_xgb]), axis=0)\n",
    "    test_meta['pred_max'] = np.max(np.vstack([pred_test_cat, pred_test_lgb, pred_test_xgb]), axis=0)\n",
    "    test_meta['pred_min'] = np.min(np.vstack([pred_test_cat, pred_test_lgb, pred_test_xgb]), axis=0)\n",
    "\n",
    "    final_predictions = final_test_predictions_blended\n",
    "\n",
    "\n",
    "# ---------------- OTHER METHODS ----------------\n",
    "elif best_method == 'Rank Averaging':\n",
    "    final_predictions = rank_average(pred_test_cat, pred_test_lgb, pred_test_xgb)\n",
    "\n",
    "elif best_method == 'Weighted Averaging':\n",
    "    final_predictions = w_cat * pred_test_cat + w_lgb * pred_test_lgb + w_xgb * pred_test_xgb\n",
    "\n",
    "elif best_method == 'Simple Averaging':\n",
    "    final_predictions = (pred_test_cat + pred_test_lgb + pred_test_xgb) / 3\n",
    "\n",
    "elif best_method == 'Pseudo-labeled CatBoost':\n",
    "    catboost_pseudo.fit(X_full, y_full)\n",
    "    final_predictions = catboost_pseudo.predict_proba(test_full)[:, 1]\n",
    "\n",
    "else:  # Default to optimized CatBoost\n",
    "    final_predictions = pred_test_cat\n",
    "\n",
    "\n",
    "# ---------------- SAVE SUBMISSION ----------------\n",
    "test_ids = test[ID_COL] if ID_COL in test.columns else range(len(test))\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'target': final_predictions\n",
    "})\n",
    "\n",
    "filename = f'submission_final_optimized_{best_score:.4f}.csv'\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Submission created: {filename}\")\n",
    "print(f\"   Method: {best_method}\")\n",
    "print(f\"   Validation AUROC: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating additional submissions for top 3 methods...\n",
      "  Creating submission for: CatBoost (Optimized) (AUROC: 0.636064)\n",
      "    ‚úÖ submission_catboost_optimized_0.636064.csv\n",
      "  Creating submission for: Pseudo-labeled CatBoost (AUROC: 0.636064)\n",
      "    ‚úÖ submission_pseudo-labeled_catboost_0.636064.csv\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# CREATE ADDITIONAL SUBMISSIONS FOR TOP 3 METHODS  (S2 Compatible)\n",
    "# ========================================================================\n",
    "print(\"\\nCreating additional submissions for top 3 methods...\")\n",
    "\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (method, score) in enumerate(sorted_results[:3]):\n",
    "    if method == best_method:\n",
    "        continue  # Already created\n",
    "\n",
    "    print(f\"  Creating submission for: {method} (AUROC: {score:.6f})\")\n",
    "\n",
    "    # ---------------- STACKING CASE (S2 FULL-DATA) ----------------\n",
    "    if method == 'Multi-layer Stacking':\n",
    "        test_meta = test_full.copy()\n",
    "        test_meta['pred_cat'] = pred_test_cat\n",
    "        test_meta['pred_lgb'] = pred_test_lgb\n",
    "        test_meta['pred_xgb'] = pred_test_xgb\n",
    "        test_meta['pred_avg'] = (pred_test_cat + pred_test_lgb + pred_test_xgb) / 3\n",
    "        test_meta['pred_std'] = np.std(np.vstack([pred_test_cat, pred_test_lgb, pred_test_xgb]), axis=0)\n",
    "        test_meta['pred_max'] = np.max(np.vstack([pred_test_cat, pred_test_lgb, pred_test_xgb]), axis=0)\n",
    "        test_meta['pred_min'] = np.min(np.vstack([pred_test_cat, pred_test_lgb, pred_test_xgb]), axis=0)\n",
    "\n",
    "        preds = meta_model.predict_proba(test_meta)[:, 1]\n",
    "\n",
    "    # ---------------- OTHER METHODS ----------------\n",
    "    elif method == 'Rank Averaging':\n",
    "        preds = rank_average(pred_test_cat, pred_test_lgb, pred_test_xgb)\n",
    "\n",
    "    elif method == 'Weighted Averaging':\n",
    "        preds = w_cat * pred_test_cat + w_lgb * pred_test_lgb + w_xgb * pred_test_xgb\n",
    "\n",
    "    elif method == 'Simple Averaging':\n",
    "        preds = (pred_test_cat + pred_test_lgb + pred_test_xgb) / 3\n",
    "\n",
    "    elif method == 'Pseudo-labeled CatBoost':\n",
    "        preds = catboost_pseudo.predict_proba(test_full)[:, 1]\n",
    "\n",
    "    elif method == 'CatBoost (Optimized)':\n",
    "        preds = pred_test_cat\n",
    "\n",
    "    elif method == 'LightGBM':\n",
    "        preds = pred_test_lgb\n",
    "\n",
    "    elif method == 'XGBoost':\n",
    "        preds = pred_test_xgb\n",
    "\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è Skipping unsupported method: {method}\")\n",
    "        continue\n",
    "\n",
    "    sub = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'target': preds\n",
    "    })\n",
    "\n",
    "    fname = f\"submission_{method.lower().replace(' ', '_').replace('(', '').replace(')', '')}_{score:.6f}.csv\"\n",
    "    sub.to_csv(fname, index=False)\n",
    "    print(f\"    ‚úÖ {fname}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
