{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Models\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import time\n",
    "from matplotlib import pyplot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# reproducible seed\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching and reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (296209, 67)\n",
      "Test shape:  (126948, 66)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train1.csv')\n",
    "test  = pd.read_csv('test.csv')   # used to generate final submission\n",
    "\n",
    "# quick shape\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape: \", test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (222156, 66) X_val (74053, 66)\n",
      "Target distribution in train: {0: 0.9487342227983939, 1: 0.05126577720160608}\n",
      "Target distribution in val: {0: 0.9487259125221126, 1: 0.05127408747788746}\n"
     ]
    }
   ],
   "source": [
    "X = train.drop('target', axis=1)\n",
    "y = train['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "print(\"X_train\", X_train.shape, \"X_val\", X_val.shape)\n",
    "\n",
    "print(f\"Target distribution in train: {y_train.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Target distribution in val: {y_val.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "target\n",
      "0    281023\n",
      "1     15186\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "bin_cols = [c for c in X_train.columns if '_bin' in c]\n",
    "cat_cols = [c for c in X_train.columns if '_cat' in c]\n",
    "num_cols = [c for c in X_train.columns if c not in bin_cols + cat_cols + ['id']]\n",
    "\n",
    "# Categorical columns ‚Üí mode (most_frequent)\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "X_train[cat_cols] = imputer_cat.fit_transform(X_train[cat_cols])\n",
    "X_val[cat_cols] = imputer_cat.transform(X_val[cat_cols])\n",
    "\n",
    "# Fill numeric NaNs with median from training data\n",
    "median_vals = X_train[num_cols].median()\n",
    "X_train[num_cols] = X_train[num_cols].fillna(median_vals)\n",
    "X_val[num_cols] = X_val[num_cols].fillna(median_vals)\n",
    "\n",
    "# fill binary columns with mode\n",
    "imputer_bin = SimpleImputer(strategy='most_frequent')\n",
    "X_train[bin_cols] = imputer_bin.fit_transform(X_train[bin_cols])\n",
    "X_val[bin_cols] = imputer_bin.transform(X_val[bin_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary cols: 17\n",
      "Categorical cols: 14\n",
      "Numeric cols: 34\n",
      "Binary Columns (17): ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin'] \n",
      "\n",
      "Categorical Columns (14): ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat'] \n",
      "\n",
      "Numeric Columns (34): ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'feature1', 'feature2', 'feature3', 'feature4', 'feature5', 'feature6', 'feature7', 'feature8']\n"
     ]
    }
   ],
   "source": [
    "print(\"Binary cols:\", len(bin_cols))\n",
    "print(\"Categorical cols:\", len(cat_cols))\n",
    "print(\"Numeric cols:\", len(num_cols))\n",
    "\n",
    "print(\"Binary Columns ({}):\".format(len(bin_cols)), bin_cols, \"\\n\")\n",
    "print(\"Categorical Columns ({}):\".format(len(cat_cols)), cat_cols, \"\\n\")\n",
    "print(\"Numeric Columns ({}):\".format(len(num_cols)), num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum().sum(), X_val.isna().sum().sum() #no more Na columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categorical (_cat) columns to category dtype\n",
    "for c in cat_cols:\n",
    "    X_train[c] = X_train[c].astype('category')\n",
    "    X_val[c] = X_val[c].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64       37\n",
       "float64     15\n",
       "category     6\n",
       "category     1\n",
       "category     1\n",
       "category     1\n",
       "category     1\n",
       "category     1\n",
       "category     1\n",
       "category     1\n",
       "category     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "preprocessor_cnb = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
    "    ('bin', 'passthrough', bin_cols)\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor_gnb = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('bin', 'passthrough', bin_cols)\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor_knn = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
    "    ('bin', 'passthrough', bin_cols)\n",
    "])\n",
    "\n",
    "\n",
    "# No scaling or encoding required\n",
    "preprocessor_tree = ColumnTransformer([\n",
    "    ('num', 'passthrough', num_cols),\n",
    "    ('cat', 'passthrough', cat_cols),\n",
    "    ('bin', 'passthrough', bin_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Models defined successfully with preprocessing pipelines.\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# üß† DEFINE BASE MODELS (no hyperparameters yet)\n",
    "# ===========================\n",
    "\n",
    "models = {\n",
    "    \"CategoricalNB\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor_cnb),\n",
    "        (\"model\", CategoricalNB())\n",
    "    ]),\n",
    "\n",
    "    \"GaussianNB\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor_gnb),\n",
    "        (\"model\", GaussianNB())\n",
    "    ]),\n",
    "\n",
    "    \"KNN\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor_knn),\n",
    "        (\"model\", KNeighborsClassifier())\n",
    "    ]),\n",
    "\n",
    "    \"DecisionTree\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor_tree),\n",
    "        (\"model\", DecisionTreeClassifier(random_state=42))\n",
    "    ]),\n",
    "\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor_tree),\n",
    "        (\"model\", RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "\n",
    "    \"AdaBoost\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor_tree),\n",
    "        (\"model\", AdaBoostClassifier(random_state=42))\n",
    "    ]),\n",
    "\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor_tree),\n",
    "        (\"model\", xgb.XGBClassifier(\n",
    "            random_state=42,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss'\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    \"LightGBM\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor_tree),\n",
    "        (\"model\", lgb.LGBMClassifier(random_state=42))\n",
    "    ]),\n",
    "\n",
    "    \"CatBoost\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor_tree),\n",
    "        (\"model\", CatBoostClassifier(\n",
    "            verbose=0,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "print(\"‚úÖ Models defined successfully with preprocessing pipelines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# üéõÔ∏è DEFINE HYPERPARAMETER GRIDS (lightweight)\n",
    "# ===========================\n",
    "\n",
    "param_grids = {\n",
    "\n",
    "    # --- Categorical Naive Bayes ---\n",
    "    \"CategoricalNB\": {\n",
    "        \"model__alpha\": [0.5, 1.0, 2.0]\n",
    "    },\n",
    "\n",
    "    # --- Gaussian Naive Bayes ---\n",
    "    \"GaussianNB\": {\n",
    "        \"model__var_smoothing\": [1e-9, 1e-7]\n",
    "    },\n",
    "\n",
    "    # --- K-Nearest Neighbors ---\n",
    "    \"KNN\": {\n",
    "        \"model__n_neighbors\": [5, 7, 9],\n",
    "        \"model__weights\": [\"uniform\", \"distance\"]\n",
    "    },\n",
    "\n",
    "    # --- Decision Tree ---\n",
    "    \"DecisionTree\": {\n",
    "        \"model__criterion\": [\"gini\", \"entropy\"],\n",
    "        \"model__max_depth\": [5, 7],\n",
    "        \"model__min_samples_split\": [2, 5],\n",
    "        \"model__min_samples_leaf\": [1,2]\n",
    "    },\n",
    "\n",
    "    # --- Random Forest ---\n",
    "    \"RandomForest\": {\n",
    "        \"model__n_estimators\": [100],\n",
    "        \"model__max_depth\": [5,10],\n",
    "        \"model__min_samples_split\": [2, 5]\n",
    "    },\n",
    "\n",
    "    # --- AdaBoost ---\n",
    "    \"AdaBoost\": {\n",
    "        \"model__n_estimators\": [50, 100],\n",
    "        \"model__learning_rate\": [0.01, 0.1, 0.5]\n",
    "    },\n",
    "\n",
    "    # --- XGBoost ---\n",
    "    \"XGBoost\": {\n",
    "        \"model__n_estimators\": [100],\n",
    "        \"model__max_depth\": [3, 5],\n",
    "        \"model__learning_rate\": [0.05, 0.1],\n",
    "        \"model__subsample\": [0.8, 1.0]\n",
    "    },\n",
    "\n",
    "    # --- LightGBM ---\n",
    "    \"LightGBM\": {\n",
    "        \"model__n_estimators\": [100],\n",
    "        \"model__num_leaves\": [31, 63],\n",
    "        \"model__learning_rate\": [0.05, 0.1],\n",
    "        \"model__subsample\": [0.8, 1.0]\n",
    "    },\n",
    "\n",
    "    # --- CatBoost ---\n",
    "    \"CatBoost\": {\n",
    "        \"model__depth\": [4, 6, 8],\n",
    "        \"model__learning_rate\": [0.03, 0.1],\n",
    "        \"model__iterations\": [200]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Search CV large parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[22:19:29] üîπ Starting CategoricalNB tuning with Random Search...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "\n",
      "[22:20:14] üîπ Starting GaussianNB tuning with Random Search...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      "[22:20:24] üîπ Starting KNN tuning with Random Search...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "\n",
      "[22:58:31] üîπ Starting DecisionTree tuning with Random Search...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "\n",
      "[22:59:19] üîπ Starting RandomForest tuning with Random Search...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "\n",
      "[23:05:35] üîπ Starting AdaBoost tuning with Random Search...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "\n",
      "[23:15:43] üîπ Starting XGBoost tuning with Random Search...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "\n",
      "[23:16:40] üîπ Starting LightGBM tuning with Random Search...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 11389, number of negative: 210767\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2414\n",
      "[LightGBM] [Info] Number of data points in the train set: 222156, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051266 -> initscore=-2.918105\n",
      "[LightGBM] [Info] Start training from score -2.918105\n",
      "\n",
      "[23:17:39] üîπ Starting CatBoost tuning with Random Search...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "\n",
      "===============================\n",
      "üèÜ FINAL COMPARISON OF MODELS (Random Search)\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best AUROC</th>\n",
       "      <th>Train Time (s)</th>\n",
       "      <th>Predict Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.636402</td>\n",
       "      <td>209.99</td>\n",
       "      <td>0.23</td>\n",
       "      <td>{'model__learning_rate': 0.1, 'model__iteratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.633440</td>\n",
       "      <td>56.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'model__subsample': 0.8, 'model__n_estimators...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.633219</td>\n",
       "      <td>58.96</td>\n",
       "      <td>0.37</td>\n",
       "      <td>{'model__subsample': 1.0, 'model__num_leaves':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.625238</td>\n",
       "      <td>604.79</td>\n",
       "      <td>2.72</td>\n",
       "      <td>{'model__n_estimators': 100, 'model__learning_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.622117</td>\n",
       "      <td>375.65</td>\n",
       "      <td>1.03</td>\n",
       "      <td>{'model__n_estimators': 100, 'model__min_sampl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CategoricalNB</td>\n",
       "      <td>0.605720</td>\n",
       "      <td>43.53</td>\n",
       "      <td>1.68</td>\n",
       "      <td>{'model__alpha': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.602350</td>\n",
       "      <td>47.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'model__min_samples_split': 5, 'model__min_sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.598768</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.49</td>\n",
       "      <td>{'model__var_smoothing': 1e-09}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.521121</td>\n",
       "      <td>2110.85</td>\n",
       "      <td>176.62</td>\n",
       "      <td>{'model__weights': 'distance', 'model__n_neigh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Best AUROC  Train Time (s)  Predict Time (s)  \\\n",
       "0       CatBoost    0.636402          209.99              0.23   \n",
       "1        XGBoost    0.633440           56.28              0.25   \n",
       "2       LightGBM    0.633219           58.96              0.37   \n",
       "3       AdaBoost    0.625238          604.79              2.72   \n",
       "4   RandomForest    0.622117          375.65              1.03   \n",
       "5  CategoricalNB    0.605720           43.53              1.68   \n",
       "6   DecisionTree    0.602350           47.06              0.15   \n",
       "7     GaussianNB    0.598768            9.57              0.49   \n",
       "8            KNN    0.521121         2110.85            176.62   \n",
       "\n",
       "                                         Best Params  \n",
       "0  {'model__learning_rate': 0.1, 'model__iteratio...  \n",
       "1  {'model__subsample': 0.8, 'model__n_estimators...  \n",
       "2  {'model__subsample': 1.0, 'model__num_leaves':...  \n",
       "3  {'model__n_estimators': 100, 'model__learning_...  \n",
       "4  {'model__n_estimators': 100, 'model__min_sampl...  \n",
       "5                              {'model__alpha': 0.5}  \n",
       "6  {'model__min_samples_split': 5, 'model__min_sa...  \n",
       "7                    {'model__var_smoothing': 1e-09}  \n",
       "8  {'model__weights': 'distance', 'model__n_neigh...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Best tuned model: CatBoost (AUROC = 0.6364)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through each model\n",
    "for name, (prep, model) in models.items():\n",
    "    print(f\"\\n[{time.strftime('%H:%M:%S')}] üîπ Starting {name} tuning with Random Search...\")\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', prep),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # --- Training time ---\n",
    "    start_train = time.time()\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_grids[name],\n",
    "        n_iter=5,                 # number of random combinations to try (tune as needed)\n",
    "        scoring='roc_auc',\n",
    "        cv=3,\n",
    "        n_jobs=1,                 # use all cores for speed\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    # --- Prediction time ---\n",
    "    best_model = random_search.best_estimator_\n",
    "    start_pred = time.time()\n",
    "    y_pred = best_model.predict_proba(X_val)[:, 1]\n",
    "    pred_time = time.time() - start_pred\n",
    "\n",
    "    # --- AUROC ---\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Best AUROC': auc,\n",
    "        'Train Time (s)': round(train_time, 2),\n",
    "        'Predict Time (s)': round(pred_time, 2),\n",
    "        'Best Params': random_search.best_params_\n",
    "    })\n",
    "\n",
    "# --- Results summary ---\n",
    "results_df = pd.DataFrame(results).sort_values(by='Best AUROC', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n===============================\")\n",
    "print(\"üèÜ FINAL COMPARISON OF MODELS (Random Search)\")\n",
    "print(\"===============================\")\n",
    "display(results_df)\n",
    "\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_auc = results_df.iloc[0]['Best AUROC']\n",
    "print(f\"\\nüèÜ Best tuned model: {best_model_name} (AUROC = {best_auc:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search CV on narrow hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Fine-tuning CatBoost...\n",
      "  ‚û§ Testing 36 hyperparameter combinations:\n",
      "     model__depth: [5, 6, 7]\n",
      "     model__learning_rate: [0.05, 0.1]\n",
      "     model__iterations: [300, 500]\n",
      "     model__l2_leaf_reg: [3, 5, 7]\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  23.6s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  20.7s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  20.7s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  20.7s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  21.7s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  20.6s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  20.8s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  20.7s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  21.4s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  24.1s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  22.7s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  21.1s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  21.1s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  21.5s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  21.6s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  21.0s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  20.3s\n",
      "[CV] END model__depth=5, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  22.9s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  38.1s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  36.8s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  36.3s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  33.2s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  35.8s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  33.2s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  33.6s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  35.9s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  32.9s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  32.8s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  33.2s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  33.0s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  36.0s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  31.6s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  34.5s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  33.6s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  32.7s\n",
      "[CV] END model__depth=5, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  34.5s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  24.0s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  22.9s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  22.8s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  22.7s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  23.1s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  24.0s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  22.6s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  22.2s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  24.3s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  24.6s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  22.2s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  23.3s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  23.4s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  22.3s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  23.4s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  24.8s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  23.9s\n",
      "[CV] END model__depth=6, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  22.8s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  39.3s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  35.7s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  36.6s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  39.1s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  35.8s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  42.5s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  33.3s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  28.7s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  27.2s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  27.0s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  26.9s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  26.9s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  26.8s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  28.4s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  28.0s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  27.2s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  27.0s\n",
      "[CV] END model__depth=6, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  27.0s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  19.1s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  19.3s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  19.9s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  19.5s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  19.2s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  19.4s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  19.0s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  18.8s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  18.9s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  18.5s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  19.0s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  19.4s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  19.6s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  18.4s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  18.5s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  19.6s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  18.2s\n",
      "[CV] END model__depth=7, model__iterations=300, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  19.1s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  30.6s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  30.5s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.05; total time=  30.5s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  30.5s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  33.2s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=3, model__learning_rate=0.1; total time=  31.0s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  32.4s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  37.9s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.05; total time=  35.1s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  30.8s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  31.7s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=5, model__learning_rate=0.1; total time=  31.0s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  31.7s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  31.2s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.05; total time=  31.5s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  33.6s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  31.2s\n",
      "[CV] END model__depth=7, model__iterations=500, model__l2_leaf_reg=7, model__learning_rate=0.1; total time=  31.3s\n",
      "\n",
      "‚úÖ Best hyperparameters for CatBoost:\n",
      "     model__depth: 6\n",
      "     model__iterations: 300\n",
      "     model__l2_leaf_reg: 3\n",
      "     model__learning_rate: 0.05\n",
      "üéØ CatBoost AUROC on validation set: 0.636566\n",
      "\n",
      "üîπ Fine-tuning XGBoost...\n",
      "  ‚û§ Testing 48 hyperparameter combinations:\n",
      "     model__max_depth: [4, 5, 6]\n",
      "     model__learning_rate: [0.05, 0.1]\n",
      "     model__n_estimators: [200, 400]\n",
      "     model__subsample: [0.8, 1.0]\n",
      "     model__colsample_bytree: [0.8, 1.0]\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   6.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   5.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   5.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=  10.0s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=  10.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=  10.0s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   8.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   7.9s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   7.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   5.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   6.9s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=  12.0s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  16.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  11.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  11.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   8.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   8.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=  10.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   7.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   7.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   7.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   6.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   6.0s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   6.0s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=  11.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=  10.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=   9.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   5.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   5.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   5.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.4s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=  10.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=   9.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=   9.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   8.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   8.0s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   7.7s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.0s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   5.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   5.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   5.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  10.9s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  11.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  10.9s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   8.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   8.9s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   8.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   7.0s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   6.6s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   8.3s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   6.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   5.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   6.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.5s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.2s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=   9.8s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=  10.1s\n",
      "[CV] END model__colsample_bytree=0.8, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=  10.3s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   5.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   5.9s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   5.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   5.3s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=   9.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=  10.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=  10.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   7.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   7.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   7.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.3s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   5.4s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   5.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   5.4s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  10.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  11.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  10.9s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   8.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   9.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   9.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   6.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   6.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   6.9s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   5.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   5.9s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   5.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.5s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.3s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=  10.4s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=   9.9s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.05, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=  10.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   6.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   5.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=0.8; total time=   5.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=200, model__subsample=1.0; total time=   4.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=   9.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=   9.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=0.8; total time=  10.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   8.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   7.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=4, model__n_estimators=400, model__subsample=1.0; total time=   8.4s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   6.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=0.8; total time=   7.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   5.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   5.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=200, model__subsample=1.0; total time=   5.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  11.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  11.3s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=0.8; total time=  10.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   8.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   8.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=5, model__n_estimators=400, model__subsample=1.0; total time=   8.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   6.9s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   7.0s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=0.8; total time=   6.7s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   5.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   5.5s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=200, model__subsample=1.0; total time=   5.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.1s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.6s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=0.8; total time=  12.5s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=  10.2s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=   9.8s\n",
      "[CV] END model__colsample_bytree=1.0, model__learning_rate=0.1, model__max_depth=6, model__n_estimators=400, model__subsample=1.0; total time=  10.5s\n",
      "\n",
      "‚úÖ Best hyperparameters for XGBoost:\n",
      "     model__colsample_bytree: 0.8\n",
      "     model__learning_rate: 0.05\n",
      "     model__max_depth: 4\n",
      "     model__n_estimators: 200\n",
      "     model__subsample: 0.8\n",
      "üéØ XGBoost AUROC on validation set: 0.635004\n",
      "\n",
      "üîπ Fine-tuning LightGBM...\n",
      "  ‚û§ Testing 24 hyperparameter combinations:\n",
      "     model__num_leaves: [15, 31, 63]\n",
      "     model__learning_rate: [0.05, 0.1]\n",
      "     model__n_estimators: [200, 400]\n",
      "     model__subsample: [0.8, 1.0]\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=15, model__subsample=0.8; total time=   6.3s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=15, model__subsample=0.8; total time=   4.4s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=15, model__subsample=0.8; total time=   4.3s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=15, model__subsample=1.0; total time=   4.2s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=15, model__subsample=1.0; total time=   4.7s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=15, model__subsample=1.0; total time=   4.3s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=31, model__subsample=0.8; total time=   4.7s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=31, model__subsample=0.8; total time=   4.5s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=31, model__subsample=0.8; total time=   4.7s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=31, model__subsample=1.0; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=31, model__subsample=1.0; total time=   5.1s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=31, model__subsample=1.0; total time=   6.4s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=63, model__subsample=0.8; total time=   5.2s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=63, model__subsample=0.8; total time=   5.2s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=63, model__subsample=0.8; total time=   5.7s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=63, model__subsample=1.0; total time=   5.1s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=63, model__subsample=1.0; total time=   5.4s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=200, model__num_leaves=63, model__subsample=1.0; total time=   5.5s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=15, model__subsample=0.8; total time=   6.3s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=15, model__subsample=0.8; total time=   6.5s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=15, model__subsample=0.8; total time=   6.6s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=15, model__subsample=1.0; total time=   6.3s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=15, model__subsample=1.0; total time=   7.0s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=15, model__subsample=1.0; total time=   6.7s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=31, model__subsample=0.8; total time=   7.8s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=31, model__subsample=0.8; total time=   7.3s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=31, model__subsample=0.8; total time=   7.2s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=31, model__subsample=1.0; total time=   7.0s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=31, model__subsample=1.0; total time=   7.1s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=31, model__subsample=1.0; total time=   7.0s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=63, model__subsample=0.8; total time=   9.8s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=63, model__subsample=0.8; total time=   8.5s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=63, model__subsample=0.8; total time=   8.2s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=63, model__subsample=1.0; total time=   8.4s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=63, model__subsample=1.0; total time=   8.1s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.05, model__n_estimators=400, model__num_leaves=63, model__subsample=1.0; total time=   8.2s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=15, model__subsample=0.8; total time=   4.0s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=15, model__subsample=0.8; total time=   4.2s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=15, model__subsample=0.8; total time=   3.8s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=15, model__subsample=1.0; total time=   3.9s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=15, model__subsample=1.0; total time=   3.8s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=15, model__subsample=1.0; total time=   3.9s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=31, model__subsample=0.8; total time=   6.5s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=31, model__subsample=0.8; total time=   4.2s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=31, model__subsample=0.8; total time=   4.2s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=31, model__subsample=1.0; total time=   4.1s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=31, model__subsample=1.0; total time=   4.1s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=31, model__subsample=1.0; total time=   4.6s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=63, model__subsample=0.8; total time=   4.9s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=63, model__subsample=0.8; total time=   4.9s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=63, model__subsample=0.8; total time=   5.5s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=63, model__subsample=1.0; total time=   4.9s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=63, model__subsample=1.0; total time=   6.6s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=200, model__num_leaves=63, model__subsample=1.0; total time=   5.6s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=15, model__subsample=0.8; total time=   9.4s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.265670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=15, model__subsample=0.8; total time=   9.0s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=15, model__subsample=0.8; total time=   6.0s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=15, model__subsample=1.0; total time=   6.0s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=15, model__subsample=1.0; total time=   6.4s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=15, model__subsample=1.0; total time=   6.4s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=31, model__subsample=0.8; total time=   6.9s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=31, model__subsample=0.8; total time=   7.3s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.204732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=31, model__subsample=0.8; total time=   7.5s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=31, model__subsample=1.0; total time=   6.8s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=31, model__subsample=1.0; total time=   6.9s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.136990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=31, model__subsample=1.0; total time=   9.1s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=63, model__subsample=0.8; total time=   8.2s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=63, model__subsample=0.8; total time=   8.0s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=63, model__subsample=0.8; total time=   9.0s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=63, model__subsample=1.0; total time=   8.5s\n",
      "[LightGBM] [Info] Number of positive: 7593, number of negative: 140511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2400\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918059\n",
      "[LightGBM] [Info] Start training from score -2.918059\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=63, model__subsample=1.0; total time=   8.1s\n",
      "[LightGBM] [Info] Number of positive: 7592, number of negative: 140512\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2403\n",
      "[LightGBM] [Info] Number of data points in the train set: 148104, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[CV] END model__learning_rate=0.1, model__n_estimators=400, model__num_leaves=63, model__subsample=1.0; total time=   8.1s\n",
      "[LightGBM] [Info] Number of positive: 11389, number of negative: 210767\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2414\n",
      "[LightGBM] [Info] Number of data points in the train set: 222156, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051266 -> initscore=-2.918105\n",
      "[LightGBM] [Info] Start training from score -2.918105\n",
      "\n",
      "‚úÖ Best hyperparameters for LightGBM:\n",
      "     model__learning_rate: 0.05\n",
      "     model__n_estimators: 200\n",
      "     model__num_leaves: 15\n",
      "     model__subsample: 0.8\n",
      "üéØ LightGBM AUROC on validation set: 0.635346\n",
      "\n",
      "===============================\n",
      "üèÜ FINAL COMPARISON OF TOP 3 MODELS (Fine-Tuned)\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best AUROC</th>\n",
       "      <th>Train Time (s)</th>\n",
       "      <th>Predict Time (s)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.636566</td>\n",
       "      <td>2945.27</td>\n",
       "      <td>0.57</td>\n",
       "      <td>{'model__depth': 6, 'model__iterations': 300, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.635346</td>\n",
       "      <td>459.74</td>\n",
       "      <td>0.47</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__n_estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.635004</td>\n",
       "      <td>1186.04</td>\n",
       "      <td>0.31</td>\n",
       "      <td>{'model__colsample_bytree': 0.8, 'model__learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Best AUROC  Train Time (s)  Predict Time (s)  \\\n",
       "0  CatBoost    0.636566         2945.27              0.57   \n",
       "1  LightGBM    0.635346          459.74              0.47   \n",
       "2   XGBoost    0.635004         1186.04              0.31   \n",
       "\n",
       "                                         Best Params  \n",
       "0  {'model__depth': 6, 'model__iterations': 300, ...  \n",
       "1  {'model__learning_rate': 0.05, 'model__n_estim...  \n",
       "2  {'model__colsample_bytree': 0.8, 'model__learn...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÖ Best Fine-Tuned Model: CatBoost (AUROC = 0.636566)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# --- Narrow parameter grids ---\n",
    "cat_param_grid = {\n",
    "    'model__depth': [5, 6, 7],\n",
    "    'model__learning_rate': [0.05, 0.1],\n",
    "    'model__iterations': [300, 500],\n",
    "    'model__l2_leaf_reg': [3, 5, 7]\n",
    "}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'model__max_depth': [4, 5, 6],\n",
    "    'model__learning_rate': [0.05, 0.1],\n",
    "    'model__n_estimators': [200, 400],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    'model__num_leaves': [15, 31, 63],\n",
    "    'model__learning_rate': [0.05, 0.1],\n",
    "    'model__n_estimators': [200, 400],\n",
    "    'model__subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "param_grids_top3 = {\n",
    "    'CatBoost': cat_param_grid,\n",
    "    'XGBoost': xgb_param_grid,\n",
    "    'LightGBM': lgbm_param_grid\n",
    "}\n",
    "\n",
    "# --- Reuse your preprocessor ---\n",
    "preprocessor_tree = ColumnTransformer([\n",
    "    ('num', 'passthrough', num_cols),\n",
    "    ('cat', 'passthrough', cat_cols),\n",
    "    ('bin', 'passthrough', bin_cols)\n",
    "])\n",
    "\n",
    "# --- Define top 3 models ---\n",
    "models_top3 = {\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# --- Run Grid Search for each ---\n",
    "results_top3 = []\n",
    "\n",
    "for name, model in models_top3.items():\n",
    "    print(f\"\\nüîπ Fine-tuning {name}...\")\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor_tree),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    param_grid = param_grids_top3[name]\n",
    "\n",
    "    # üîç Show parameter combinations being tested\n",
    "    total_combos = 1\n",
    "    for k in param_grid:\n",
    "        total_combos *= len(param_grid[k])\n",
    "    print(f\"  ‚û§ Testing {total_combos} hyperparameter combinations:\")\n",
    "    for param, values in param_grid.items():\n",
    "        print(f\"     {param}: {values}\")\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grids_top3[name],\n",
    "        cv=3,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=1,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    start_train = time.time()\n",
    "    grid.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_train\n",
    "    \n",
    "    # ‚úÖ Show best found hyperparameters\n",
    "    print(f\"\\n‚úÖ Best hyperparameters for {name}:\")\n",
    "    for k, v in grid.best_params_.items():\n",
    "        print(f\"     {k}: {v}\")\n",
    "\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    start_pred = time.time()\n",
    "    y_pred = best_model.predict_proba(X_val)[:, 1]\n",
    "    pred_time = time.time() - start_pred\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    print(f\"üéØ {name} AUROC on validation set: {auc:.6f}\")\n",
    "\n",
    "\n",
    "    results_top3.append({\n",
    "        'Model': name,\n",
    "        'Best AUROC': round(auc, 6),\n",
    "        'Train Time (s)': round(train_time, 2),\n",
    "        'Predict Time (s)': round(pred_time, 2),\n",
    "        'Best Params': grid.best_params_\n",
    "    })\n",
    "\n",
    "# --- Show comparison ---\n",
    "results_top3_df = pd.DataFrame(results_top3).sort_values(by='Best AUROC', ascending=False).reset_index(drop=True)\n",
    "print(\"\\n===============================\")\n",
    "print(\"üèÜ FINAL COMPARISON OF TOP 3 MODELS (Fine-Tuned)\")\n",
    "print(\"===============================\")\n",
    "display(results_top3_df)\n",
    "\n",
    "best_model_name = results_top3_df.iloc[0]['Model']\n",
    "print(f\"\\nüèÖ Best Fine-Tuned Model: {best_model_name} (AUROC = {results_top3_df.iloc[0]['Best AUROC']})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full data train + File creation for top 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÅ Retraining CatBoost on 100% training data with tuned parameters...\n",
      "‚úÖ CatBoost training complete in 34.24s\n",
      "‚úÖ CatBoost predictions complete in 0.29s\n",
      "üìÅ submission_catboost.csv created successfully!\n",
      "\n",
      "üèÅ Retraining LightGBM on 100% training data with tuned parameters...\n",
      "[LightGBM] [Info] Number of positive: 15186, number of negative: 281023\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2423\n",
      "[LightGBM] [Info] Number of data points in the train set: 296209, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918063\n",
      "[LightGBM] [Info] Start training from score -2.918063\n",
      "‚úÖ LightGBM training complete in 8.12s\n",
      "‚úÖ LightGBM predictions complete in 0.88s\n",
      "üìÅ submission_lightgbm.csv created successfully!\n",
      "\n",
      "üèÅ Retraining XGBoost on 100% training data with tuned parameters...\n",
      "‚úÖ XGBoost training complete in 13.79s\n",
      "‚úÖ XGBoost predictions complete in 0.57s\n",
      "üìÅ submission_xgboost.csv created successfully!\n",
      "\n",
      "üéØ All top 3 models retrained and submission files generated!\n"
     ]
    }
   ],
   "source": [
    "# === Final Training and Kaggle Submissions for Top 3 Models ===\n",
    "import joblib\n",
    "\n",
    "# --- Load full train/test datasets ---\n",
    "train_full = pd.read_csv(\"train1.csv\")\n",
    "test_full = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Separate target\n",
    "y_full = train_full['target']\n",
    "X_full = train_full.drop(['target', 'id'], axis=1)\n",
    "test_ids = test_full['id']\n",
    "X_test = test_full.drop(['id'], axis=1)\n",
    "\n",
    "# --- Define the top 3 best parameter sets from your fine-tuned GridSearch ---\n",
    "best_params_dict = {\n",
    "    \"CatBoost\": {\n",
    "        'iterations': 300,\n",
    "        'depth': 6,\n",
    "        'learning_rate': 0.05,\n",
    "        'l2_leaf_reg': 3\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'num_leaves': 15,\n",
    "        'learning_rate': 0.05,\n",
    "        'n_estimators': 200,\n",
    "        'subsample': 0.8\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.05,\n",
    "        'n_estimators': 200,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Initialize models ---\n",
    "models_top3 = {\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42, **best_params_dict[\"CatBoost\"]),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(random_state=42, **best_params_dict[\"LightGBM\"]),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, **best_params_dict[\"XGBoost\"])\n",
    "}\n",
    "\n",
    "# --- Loop over each top model for final training ---\n",
    "for model_name, model in models_top3.items():\n",
    "    print(f\"\\nüèÅ Retraining {model_name} on 100% training data with tuned parameters...\")\n",
    "\n",
    "    # Create pipeline with preprocessor\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor_tree),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # --- Training ---\n",
    "    start_train = time.time()\n",
    "    pipe.fit(X_full, y_full)\n",
    "    train_time = time.time() - start_train\n",
    "    print(f\"‚úÖ {model_name} training complete in {train_time:.2f}s\")\n",
    "\n",
    "    # Save trained model\n",
    "    joblib.dump(pipe, f\"{model_name}_final.pkl\")\n",
    "\n",
    "    # --- Prediction ---\n",
    "    start_pred = time.time()\n",
    "    test_preds = pipe.predict_proba(X_test)[:, 1]\n",
    "    pred_time = time.time() - start_pred\n",
    "    print(f\"‚úÖ {model_name} predictions complete in {pred_time:.2f}s\")\n",
    "\n",
    "    # --- Create submission DataFrame ---\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'target': test_preds\n",
    "    })\n",
    "\n",
    "    # --- Save submission file ---\n",
    "    filename = f\"submission_{model_name.lower()}.csv\"\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(f\"üìÅ {filename} created successfully!\")\n",
    "\n",
    "print(\"\\nüéØ All top 3 models retrained and submission files generated!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking Ensemble of the top3 models (CatB + xgb + lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ù Training Stacking Ensemble (Validation Mode)...\n",
      "[LightGBM] [Info] Number of positive: 11389, number of negative: 210767\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2414\n",
      "[LightGBM] [Info] Number of data points in the train set: 222156, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051266 -> initscore=-2.918105\n",
      "[LightGBM] [Info] Start training from score -2.918105\n",
      "[LightGBM] [Info] Number of positive: 9111, number of negative: 168613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2410\n",
      "[LightGBM] [Info] Number of data points in the train set: 177724, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051265 -> initscore=-2.918124\n",
      "[LightGBM] [Info] Start training from score -2.918124\n",
      "[LightGBM] [Info] Number of positive: 9112, number of negative: 168613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2409\n",
      "[LightGBM] [Info] Number of data points in the train set: 177725, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918014\n",
      "[LightGBM] [Info] Start training from score -2.918014\n",
      "[LightGBM] [Info] Number of positive: 9111, number of negative: 168614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2406\n",
      "[LightGBM] [Info] Number of data points in the train set: 177725, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051265 -> initscore=-2.918130\n",
      "[LightGBM] [Info] Start training from score -2.918130\n",
      "[LightGBM] [Info] Number of positive: 9111, number of negative: 168614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2406\n",
      "[LightGBM] [Info] Number of data points in the train set: 177725, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051265 -> initscore=-2.918130\n",
      "[LightGBM] [Info] Start training from score -2.918130\n",
      "[LightGBM] [Info] Number of positive: 9111, number of negative: 168614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2408\n",
      "[LightGBM] [Info] Number of data points in the train set: 177725, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051265 -> initscore=-2.918130\n",
      "[LightGBM] [Info] Start training from score -2.918130\n",
      "‚úÖ Ensemble trained in 260.37s\n",
      "‚úÖ Validation predictions complete in 1.04s\n",
      "\n",
      "üìä Validation AUROC for Stacking Ensemble: 0.637070\n"
     ]
    }
   ],
   "source": [
    "# === Step 2.8: Stacking Ensemble of Top 3 Tuned Models ===\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# --- Base models (using the tuned hyperparameters) ---\n",
    "base_models = [\n",
    "    ('catboost', CatBoostClassifier(verbose=0, random_state=42, **best_params_dict[\"CatBoost\"])),\n",
    "    ('lightgbm', lgb.LGBMClassifier(random_state=42, **best_params_dict[\"LightGBM\"])),\n",
    "    ('xgboost', xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, **best_params_dict[\"XGBoost\"]))\n",
    "]\n",
    "\n",
    "# --- Meta-model (simple and strong for stacking) ---\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# --- Build the stacking ensemble ---\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,                # 5-fold stacking\n",
    "    stack_method='predict_proba',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# --- Create pipeline with preprocessor ---\n",
    "stack_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor_tree),\n",
    "    ('stacking', stacking_model)\n",
    "])\n",
    "\n",
    "# --- Train on training split ---\n",
    "print(\"\\nü§ù Training Stacking Ensemble (Validation Mode)...\")\n",
    "start_train = time.time()\n",
    "stack_pipe.fit(X_train, y_train)\n",
    "train_time = time.time() - start_train\n",
    "print(f\"‚úÖ Ensemble trained in {train_time:.2f}s\")\n",
    "\n",
    "# --- Evaluate on validation split ---\n",
    "start_pred = time.time()\n",
    "y_val_pred = stack_pipe.predict_proba(X_val)[:, 1]\n",
    "pred_time = time.time() - start_pred\n",
    "val_auc = roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"‚úÖ Validation predictions complete in {pred_time:.2f}s\")\n",
    "print(f\"\\nüìä Validation AUROC for Stacking Ensemble: {val_auc:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ù Training Stacking Ensemble on top of CatBoost, LightGBM, and XGBoost...\n",
      "[LightGBM] [Info] Number of positive: 15186, number of negative: 281023\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2423\n",
      "[LightGBM] [Info] Number of data points in the train set: 296209, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918063\n",
      "[LightGBM] [Info] Start training from score -2.918063\n",
      "[LightGBM] [Info] Number of positive: 12149, number of negative: 224818\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2425\n",
      "[LightGBM] [Info] Number of data points in the train set: 236967, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051269 -> initscore=-2.918044\n",
      "[LightGBM] [Info] Start training from score -2.918044\n",
      "[LightGBM] [Info] Number of positive: 12149, number of negative: 224818\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2423\n",
      "[LightGBM] [Info] Number of data points in the train set: 236967, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051269 -> initscore=-2.918044\n",
      "[LightGBM] [Info] Start training from score -2.918044\n",
      "[LightGBM] [Info] Number of positive: 12149, number of negative: 224818\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2421\n",
      "[LightGBM] [Info] Number of data points in the train set: 236967, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051269 -> initscore=-2.918044\n",
      "[LightGBM] [Info] Start training from score -2.918044\n",
      "[LightGBM] [Info] Number of positive: 12148, number of negative: 224819\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2418\n",
      "[LightGBM] [Info] Number of data points in the train set: 236967, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051265 -> initscore=-2.918131\n",
      "[LightGBM] [Info] Start training from score -2.918131\n",
      "[LightGBM] [Info] Number of positive: 12149, number of negative: 224819\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2423\n",
      "[LightGBM] [Info] Number of data points in the train set: 236968, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051269 -> initscore=-2.918049\n",
      "[LightGBM] [Info] Start training from score -2.918049\n",
      "‚úÖ Stacking Ensemble training complete in 311.42s\n",
      "‚úÖ Ensemble predictions complete in 1.80s\n",
      "üìÅ submission_stacking_ensemble.csv created successfully!\n",
      "\n",
      "üèÜ Stacking Ensemble completed and ready for submission!\n"
     ]
    }
   ],
   "source": [
    "# --- Train the ensemble on the full training data ---\n",
    "print(\"\\nü§ù Training Stacking Ensemble on top of CatBoost, LightGBM, and XGBoost...\")\n",
    "\n",
    "start_train = time.time()\n",
    "stack_pipe.fit(X_full, y_full)\n",
    "train_time = time.time() - start_train\n",
    "print(f\"‚úÖ Stacking Ensemble training complete in {train_time:.2f}s\")\n",
    "\n",
    "# --- Save the stacked model ---\n",
    "joblib.dump(stack_pipe, \"Stacking_Ensemble_final.pkl\")\n",
    "\n",
    "# --- Predict on test data ---\n",
    "start_pred = time.time()\n",
    "stack_preds = stack_pipe.predict_proba(X_test)[:, 1]\n",
    "pred_time = time.time() - start_pred\n",
    "print(f\"‚úÖ Ensemble predictions complete in {pred_time:.2f}s\")\n",
    "\n",
    "# --- Create submission DataFrame ---\n",
    "submission_stack = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'target': stack_preds\n",
    "})\n",
    "\n",
    "# --- Save submission file ---\n",
    "submission_file = \"submission_stacking_ensemble.csv\"\n",
    "submission_stack.to_csv(submission_file, index=False)\n",
    "print(f\"üìÅ {submission_file} created successfully!\")\n",
    "\n",
    "print(\"\\nüèÜ Stacking Ensemble completed and ready for submission!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning stacking ensemble meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Tuning meta-model (Logistic Regression) inside stacking ensemble...\n",
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 2.0min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.1min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 2.2min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.9min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.9min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 3.1min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.5min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 2.0min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 2.3min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 3.1min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.355016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 3.0min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 2.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 2.9min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 4.0min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 3.2min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 2.1min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 2.2min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 3.5min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 3.2min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.9min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.9min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.4min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 2.0min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.9min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.1min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 3.0min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 3.7min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 2.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 3.0min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.150584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 3.6min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 2.6min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.6min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.7min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 2.3min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 2.0min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.5min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.7min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 2.0min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 3.2min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.6min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 2.0min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.6min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.7min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.7min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.2min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.4min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.4min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.4min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1000, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.5min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.7min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l2, final_estimator__solver=saga; total time= 2.7min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.7min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=lbfgs; total time= 1.8min\n",
      "[LightGBM] [Info] Number of positive: 5695, number of negative: 105383\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2393\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918013\n",
      "[LightGBM] [Info] Start training from score -2.918013\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2390\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2385\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051271 -> initscore=-2.918008\n",
      "[LightGBM] [Info] Start training from score -2.918008\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2387\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.7min\n",
      "[LightGBM] [Info] Number of positive: 5694, number of negative: 105384\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2394\n",
      "[LightGBM] [Info] Number of data points in the train set: 111078, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051261 -> initscore=-2.918198\n",
      "[LightGBM] [Info] Start training from score -2.918198\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2388\n",
      "[LightGBM] [Info] Number of data points in the train set: 88862, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918239\n",
      "[LightGBM] [Info] Start training from score -2.918239\n",
      "[LightGBM] [Info] Number of positive: 4556, number of negative: 84307\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2391\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918020\n",
      "[LightGBM] [Info] Start training from score -2.918020\n",
      "[LightGBM] [Info] Number of positive: 4555, number of negative: 84308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2392\n",
      "[LightGBM] [Info] Number of data points in the train set: 88863, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051259 -> initscore=-2.918251\n",
      "[LightGBM] [Info] Start training from score -2.918251\n",
      "[CV] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=1500, final_estimator__penalty=l1, final_estimator__solver=saga; total time= 2.7min\n",
      "[LightGBM] [Info] Number of positive: 11389, number of negative: 210767\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2414\n",
      "[LightGBM] [Info] Number of data points in the train set: 222156, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051266 -> initscore=-2.918105\n",
      "[LightGBM] [Info] Start training from score -2.918105\n",
      "[LightGBM] [Info] Number of positive: 9111, number of negative: 168613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2410\n",
      "[LightGBM] [Info] Number of data points in the train set: 177724, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051265 -> initscore=-2.918124\n",
      "[LightGBM] [Info] Start training from score -2.918124\n",
      "[LightGBM] [Info] Number of positive: 9112, number of negative: 168613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2409\n",
      "[LightGBM] [Info] Number of data points in the train set: 177725, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051270 -> initscore=-2.918014\n",
      "[LightGBM] [Info] Start training from score -2.918014\n",
      "[LightGBM] [Info] Number of positive: 9111, number of negative: 168614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2406\n",
      "[LightGBM] [Info] Number of data points in the train set: 177725, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051265 -> initscore=-2.918130\n",
      "[LightGBM] [Info] Start training from score -2.918130\n",
      "[LightGBM] [Info] Number of positive: 9111, number of negative: 168614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2406\n",
      "[LightGBM] [Info] Number of data points in the train set: 177725, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051265 -> initscore=-2.918130\n",
      "[LightGBM] [Info] Start training from score -2.918130\n",
      "[LightGBM] [Info] Number of positive: 9111, number of negative: 168614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2408\n",
      "[LightGBM] [Info] Number of data points in the train set: 177725, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051265 -> initscore=-2.918130\n",
      "[LightGBM] [Info] Start training from score -2.918130\n",
      "\n",
      "‚úÖ Meta-model tuning complete in 13176.39s\n",
      "\n",
      "üèÜ Best meta-model hyperparameters:\n",
      "   final_estimator__C: 0.1\n",
      "   final_estimator__class_weight: None\n",
      "   final_estimator__max_iter: 1000\n",
      "   final_estimator__penalty: l1\n",
      "   final_estimator__solver: saga\n",
      "\n",
      "üéØ Validation AUROC (stacked ensemble): 0.63710\n",
      "‚è±Ô∏è Prediction time: 1.20s\n"
     ]
    }
   ],
   "source": [
    "# === Step: Stacking Ensemble Validation with Meta-Model Fine-Tuning ===\n",
    "\n",
    "\n",
    "# --- Define base learners (each with preprocessing) ---\n",
    "estimators = [\n",
    "    ('cat', Pipeline([\n",
    "        ('pre', preprocessor_tree),\n",
    "        ('model', models_top3['CatBoost'])\n",
    "    ])),\n",
    "    ('lgb', Pipeline([\n",
    "        ('pre', preprocessor_tree),\n",
    "        ('model', models_top3['LightGBM'])\n",
    "    ])),\n",
    "    ('xgb', Pipeline([\n",
    "        ('pre', preprocessor_tree),\n",
    "        ('model', models_top3['XGBoost'])\n",
    "    ]))\n",
    "]\n",
    "\n",
    "# --- Meta-model hyperparameter grid (Logistic Regression) ---\n",
    "meta_param_grid = {\n",
    "    'final_estimator__C': [0.01, 0.1, 1],\n",
    "    'final_estimator__solver': ['lbfgs', 'saga'],\n",
    "    'final_estimator__max_iter': [1000, 1500],\n",
    "    'final_estimator__class_weight': [None, 'balanced'],\n",
    "    'final_estimator__penalty': ['l2','l1']\n",
    "    \n",
    "}\n",
    "\n",
    "# --- Define stacking classifier with placeholder meta-model ---\n",
    "stack_base = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    stack_method='predict_proba',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# --- Grid search to tune Logistic Regression meta-model ---\n",
    "print(\"\\nüîç Tuning meta-model (Logistic Regression) inside stacking ensemble...\")\n",
    "start_tune = time.time()\n",
    "grid_meta = GridSearchCV(\n",
    "    estimator=stack_base,\n",
    "    param_grid=meta_param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=2,\n",
    "    verbose=2,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "grid_meta.fit(X_train, y_train)\n",
    "tune_time = time.time() - start_tune\n",
    "print(f\"\\n‚úÖ Meta-model tuning complete in {tune_time:.2f}s\")\n",
    "\n",
    "# --- Show best meta-model hyperparameters ---\n",
    "print(\"\\nüèÜ Best meta-model hyperparameters:\")\n",
    "for k, v in grid_meta.best_params_.items():\n",
    "    print(f\"   {k}: {v}\")\n",
    "\n",
    "# --- Evaluate tuned stacking model ---\n",
    "best_stack = grid_meta.best_estimator_\n",
    "\n",
    "start_pred = time.time()\n",
    "val_preds = best_stack.predict_proba(X_val)[:, 1]\n",
    "pred_time = time.time() - start_pred\n",
    "\n",
    "auc = roc_auc_score(y_val, val_preds)\n",
    "print(f\"\\nüéØ Validation AUROC (stacked ensemble): {auc:.5f}\")\n",
    "print(f\"‚è±Ô∏è Prediction time: {pred_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÅ Training final stacked model on 100% training data...\n",
      "[LightGBM] [Info] Number of positive: 15186, number of negative: 281023\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2423\n",
      "[LightGBM] [Info] Number of data points in the train set: 296209, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051268 -> initscore=-2.918063\n",
      "[LightGBM] [Info] Start training from score -2.918063\n",
      "[LightGBM] [Info] Number of positive: 12149, number of negative: 224818\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2425\n",
      "[LightGBM] [Info] Number of data points in the train set: 236967, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051269 -> initscore=-2.918044\n",
      "[LightGBM] [Info] Start training from score -2.918044\n",
      "[LightGBM] [Info] Number of positive: 12149, number of negative: 224818\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2423\n",
      "[LightGBM] [Info] Number of data points in the train set: 236967, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051269 -> initscore=-2.918044\n",
      "[LightGBM] [Info] Start training from score -2.918044\n",
      "[LightGBM] [Info] Number of positive: 12149, number of negative: 224818\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2421\n",
      "[LightGBM] [Info] Number of data points in the train set: 236967, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051269 -> initscore=-2.918044\n",
      "[LightGBM] [Info] Start training from score -2.918044\n",
      "[LightGBM] [Info] Number of positive: 12148, number of negative: 224819\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2418\n",
      "[LightGBM] [Info] Number of data points in the train set: 236967, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051265 -> initscore=-2.918131\n",
      "[LightGBM] [Info] Start training from score -2.918131\n",
      "[LightGBM] [Info] Number of positive: 12149, number of negative: 224819\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2423\n",
      "[LightGBM] [Info] Number of data points in the train set: 236968, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.051269 -> initscore=-2.918049\n",
      "[LightGBM] [Info] Start training from score -2.918049\n",
      "‚úÖ Training complete in 318.85s\n",
      "üíæ Model saved as 'final_stacking_model.pkl'\n",
      "\n",
      "üìä Generating predictions for submission...\n",
      "‚úÖ Predictions complete in 2.40s\n",
      "üìÅ submission_stacking_ensemble_tuned.csv created successfully!\n",
      "\n",
      "üéØ Final stacked model with tuned Logistic Regression is ready for submission!\n"
     ]
    }
   ],
   "source": [
    "# === Final Training and Submission for Stacking Ensemble (Tuned Logistic Regression) ===\n",
    "\n",
    "# --- Tuned meta-model parameters ---\n",
    "meta_model = LogisticRegression(\n",
    "    C=0.1,\n",
    "    class_weight=None,\n",
    "    max_iter=1000,\n",
    "    penalty='l1',\n",
    "    solver='saga',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Define stacking ensemble using your top 3 models ---\n",
    "final_stack_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('cat', Pipeline([\n",
    "            ('pre', preprocessor_tree),\n",
    "            ('model', models_top3['CatBoost'])\n",
    "        ])),\n",
    "        ('lgb', Pipeline([\n",
    "            ('pre', preprocessor_tree),\n",
    "            ('model', models_top3['LightGBM'])\n",
    "        ])),\n",
    "        ('xgb', Pipeline([\n",
    "            ('pre', preprocessor_tree),\n",
    "            ('model', models_top3['XGBoost'])\n",
    "        ]))\n",
    "    ],\n",
    "    final_estimator=meta_model,\n",
    "    stack_method='predict_proba',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# --- Train the stacking model ---\n",
    "print(\"\\nüèÅ Training final stacked model on 100% training data...\")\n",
    "start_train = time.time()\n",
    "final_stack_model.fit(X_full, y_full)\n",
    "train_time = time.time() - start_train\n",
    "print(f\"‚úÖ Training complete in {train_time:.2f}s\")\n",
    "\n",
    "# --- Save model ---\n",
    "joblib.dump(final_stack_model, \"final_stacking_model.pkl\")\n",
    "print(\"üíæ Model saved as 'final_stacking_model.pkl'\")\n",
    "\n",
    "# --- Predict on test set ---\n",
    "print(\"\\nüìä Generating predictions for submission...\")\n",
    "start_pred = time.time()\n",
    "stack_test_preds = final_stack_model.predict_proba(X_test)[:, 1]\n",
    "pred_time = time.time() - start_pred\n",
    "print(f\"‚úÖ Predictions complete in {pred_time:.2f}s\")\n",
    "\n",
    "# --- Create submission file ---\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'target': stack_test_preds\n",
    "})\n",
    "filename = \"submission_stacking_ensemble_tuned.csv\"\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"üìÅ {filename} created successfully!\")\n",
    "print(\"\\nüéØ Final stacked model with tuned Logistic Regression is ready for submission!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
